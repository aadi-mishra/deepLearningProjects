{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BinaryClassifier.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOgm9fHg2046MBTudIrH7It",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aadi-mishra/Deep-Learning-Projects-Keras/blob/main/BinaryClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T65faxnSOSYr"
      },
      "source": [
        "The IMDB dataset\n",
        "We are working with the IMDB dataset: a set of 50,000 highly polarized reviews from the\n",
        "Internet Movie Database. Theyâ€™re split into 25,000 reviews for training and 25,000\n",
        "reviews for testing, each set consisting of 50% negative and 50% positive reviews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1YeI9GwOGon"
      },
      "source": [
        "# Load Dataset \n",
        "from keras.datasets import imdb"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3JRjrW1O1N0"
      },
      "source": [
        "The argument num_words=10000 means we are only keeping the top 10,000 most frequently occurring words in the training data. Rare words will be discarded. This allows\n",
        "us to work with vector data of manageable size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fKPs3k1Oplu",
        "outputId": "363bde86-3dae-466c-c716-24801bd24587"
      },
      "source": [
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(\n",
        "num_words=10000)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}