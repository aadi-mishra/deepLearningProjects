{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cryptocurrencyPricePredictionUsingRNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM+kIj26sXoYt7E77ZXJljF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aadi-mishra/deepLearningProjects/blob/main/cryptocurrencyPricePredictionUsingRNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9GemlirIqni"
      },
      "source": [
        "The dataset contains time series data of Bitcoin cash, bitcoin, etherium and litecoin provided by Harrison from his [website](https://pythonprogramming.net/). This is a code along from his tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGaUy3fc3YbZ",
        "outputId": "d6eb64f4-4314-465a-fc23-b60adb8af5bc"
      },
      "source": [
        "!git clone https://github.com/aadi-mishra/deepLearningProjects.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'deepLearningProjects'...\n",
            "remote: Enumerating objects: 57, done.\u001b[K\n",
            "remote: Counting objects: 100% (57/57), done.\u001b[K\n",
            "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 57 (delta 23), reused 10 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (57/57), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cA2t-Ne4IU8J",
        "outputId": "e4306612-0319-48b9-e274-2e12a0bd88c9"
      },
      "source": [
        "%cd deepLearningProjects/data/crypto_data/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/deepLearningProjects/data/crypto_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDa9XlsD29zp"
      },
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn import preprocessing\n",
        "from collections import deque\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjB-1MAWUe6s"
      },
      "source": [
        "### Some data wrangling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_j_F1TZnIDrH",
        "outputId": "6b767e7e-b3a7-461b-9c7b-9c47d1cdd645"
      },
      "source": [
        "# df = pd.read_csv('LTC-USD.csv', names=[\"time\", \"low\", \"high\", \"open\", \"close\", \"volume\"])\n",
        "# print(df.head(10))\n",
        "\n",
        "\n",
        "def classify(current, future):\n",
        "  if float(future) > float(current):\n",
        "    return 1  # buy\n",
        "  else:\n",
        "    return 0  # don't buy \n",
        "\n",
        "main_df = pd.DataFrame()\n",
        "ratios = [\"BTC-USD\", \"LTC-USD\", \"ETH-USD\", \"BCH-USD\"]\n",
        "\n",
        "# Merging dataframe[\"close\", \"vo lume\"] columns for each currency with reference to time \n",
        "for ratio in ratios:\n",
        "  dataset = f\"{ratio}.csv\"\n",
        "  df = pd.read_csv(dataset, names=[\"time\", \"low\", \"high\", \"open\", \"close\", \"volume\"])\n",
        "  \n",
        "\n",
        "  df.rename(columns={\"close\":f\"{ratio}_close\", \"volume\":f\"{ratio}_volume\"}, inplace=True)\n",
        "  df.set_index(\"time\", inplace=True)\n",
        "  df = df[[f\"{ratio}_close\", f\"{ratio}_volume\"]]\n",
        "  print(df.head(10))\n",
        "  \n",
        "  if len(main_df) == 0:\n",
        "    main_df = df\n",
        "  else:\n",
        "    main_df = main_df.join(df)\n",
        "\n",
        "#print(main_df.head(10))\n",
        "\n",
        "for c in main_df.columns:\n",
        "  print(c)\n",
        "\n",
        "print(main_df.head(10))\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            BTC-USD_close  BTC-USD_volume\n",
            "time                                     \n",
            "1528968660    6489.549805        0.587100\n",
            "1528968720    6487.379883        7.706374\n",
            "1528968780    6479.410156        3.088252\n",
            "1528968840    6479.410156        1.404100\n",
            "1528968900    6479.979980        0.753000\n",
            "1528968960    6480.000000        1.490900\n",
            "1528969020    6477.220215        2.731950\n",
            "1528969080    6480.000000        2.174240\n",
            "1528969140    6479.990234        0.903100\n",
            "1528969200    6478.660156        3.258786\n",
            "            LTC-USD_close  LTC-USD_volume\n",
            "time                                     \n",
            "1528968660      96.580002        9.647200\n",
            "1528968720      96.660004      314.387024\n",
            "1528968780      96.570000       77.129799\n",
            "1528968840      96.500000        7.216067\n",
            "1528968900      96.389999      524.539978\n",
            "1528968960      96.519997       16.991997\n",
            "1528969020      96.440002       95.524078\n",
            "1528969080      96.470001      175.205307\n",
            "1528969140      96.400002       43.652802\n",
            "1528969200      96.400002        8.160000\n",
            "            ETH-USD_close  ETH-USD_volume\n",
            "time                                     \n",
            "1528968720      486.01001       26.019083\n",
            "1528968780      486.00000        8.449400\n",
            "1528968840      485.75000       26.994646\n",
            "1528968900      486.00000       77.355759\n",
            "1528968960      486.00000        7.503300\n",
            "1528969020      485.98999       85.877251\n",
            "1528969080      485.98999      160.915192\n",
            "1528969140      485.98999       61.371887\n",
            "1528969200      485.98999       42.687656\n",
            "1528969260      486.00000       97.693878\n",
            "            BCH-USD_close  BCH-USD_volume\n",
            "time                                     \n",
            "1528968660     871.719971        5.675361\n",
            "1528968720     870.859985       26.856577\n",
            "1528968780     870.099976        1.124300\n",
            "1528968840     870.789978        1.749862\n",
            "1528968900     870.000000        1.680500\n",
            "1528968960     869.989990        1.669014\n",
            "1528969020     869.450012        0.865200\n",
            "1528969080     869.989990       23.534929\n",
            "1528969140     870.000000        2.300000\n",
            "1528969200     870.320007        9.255514\n",
            "BTC-USD_close\n",
            "BTC-USD_volume\n",
            "LTC-USD_close\n",
            "LTC-USD_volume\n",
            "ETH-USD_close\n",
            "ETH-USD_volume\n",
            "BCH-USD_close\n",
            "BCH-USD_volume\n",
            "            BTC-USD_close  BTC-USD_volume  ...  BCH-USD_close  BCH-USD_volume\n",
            "time                                       ...                               \n",
            "1528968660    6489.549805        0.587100  ...     871.719971        5.675361\n",
            "1528968720    6487.379883        7.706374  ...     870.859985       26.856577\n",
            "1528968780    6479.410156        3.088252  ...     870.099976        1.124300\n",
            "1528968840    6479.410156        1.404100  ...     870.789978        1.749862\n",
            "1528968900    6479.979980        0.753000  ...     870.000000        1.680500\n",
            "1528968960    6480.000000        1.490900  ...     869.989990        1.669014\n",
            "1528969020    6477.220215        2.731950  ...     869.450012        0.865200\n",
            "1528969080    6480.000000        2.174240  ...     869.989990       23.534929\n",
            "1528969140    6479.990234        0.903100  ...     870.000000        2.300000\n",
            "1528969200    6478.660156        3.258786  ...     870.320007        9.255514\n",
            "\n",
            "[10 rows x 8 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPWoPTsDUmWp"
      },
      "source": [
        "### Now we have sequential data, but we also need targets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uUM16ITJ-T5",
        "outputId": "1cb86568-ebc3-4196-e997-f747a0a44eb6"
      },
      "source": [
        "SEQ_LEN = 60 # minutes of pricing data to predict ahead\n",
        "FUTURE_PERIOD_PREDICT = 3 #minutes\n",
        "RATIO_TO_PREDICT = \"LTC-USD\"  # Let's just do this one for now\n",
        "\n",
        "main_df['future'] = main_df[f\"{RATIO_TO_PREDICT}_close\"].shift(-FUTURE_PERIOD_PREDICT) # We shift the rows n steps up so the future column corresponds to n steps ahead price wrt current \n",
        "\n",
        "print(main_df.head())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            BTC-USD_close  BTC-USD_volume  ...  BCH-USD_volume     future\n",
            "time                                       ...                           \n",
            "1528968660    6489.549805        0.587100  ...        5.675361  96.500000\n",
            "1528968720    6487.379883        7.706374  ...       26.856577  96.389999\n",
            "1528968780    6479.410156        3.088252  ...        1.124300  96.519997\n",
            "1528968840    6479.410156        1.404100  ...        1.749862  96.440002\n",
            "1528968900    6479.979980        0.753000  ...        1.680500  96.470001\n",
            "\n",
            "[5 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qk6O-jVtrY0F",
        "outputId": "73061d4f-561b-43bb-e34d-8abb10fbcf8d"
      },
      "source": [
        "print(main_df[[f\"{RATIO_TO_PREDICT}_close\", \"future\"]].head())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            LTC-USD_close     future\n",
            "time                                \n",
            "1528968660      96.580002  96.500000\n",
            "1528968720      96.660004  96.389999\n",
            "1528968780      96.570000  96.519997\n",
            "1528968840      96.500000  96.440002\n",
            "1528968900      96.389999  96.470001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQ4-3xTSrld0",
        "outputId": "86260d6e-5e00-402b-9d93-a3f5a667fdfb"
      },
      "source": [
        "main_df['target'] = list(map(classify,main_df[f\"{RATIO_TO_PREDICT}_close\"], main_df[\"future\"] ))\n",
        "print(main_df[[f\"{RATIO_TO_PREDICT}_close\", \"future\", \"target\"]].head(10))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            LTC-USD_close     future  target\n",
            "time                                        \n",
            "1528968660      96.580002  96.500000       0\n",
            "1528968720      96.660004  96.389999       0\n",
            "1528968780      96.570000  96.519997       0\n",
            "1528968840      96.500000  96.440002       0\n",
            "1528968900      96.389999  96.470001       1\n",
            "1528968960      96.519997  96.400002       0\n",
            "1528969020      96.440002  96.400002       0\n",
            "1528969080      96.470001  96.400002       0\n",
            "1528969140      96.400002  96.400002       0\n",
            "1528969200      96.400002  96.400002       0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixkJi79QsupI"
      },
      "source": [
        "### Preprocessing our data, since different currencies have differenr attributes.\n",
        "* Normalize - scaling\n",
        "* Balancing - Having equal no. of Buys and Sells in our dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmbfqXQgtaNv"
      },
      "source": [
        "#### Let's separate data for testing first, We cannot randomly shuffle and select data, rather we will select a chunk of time series data, preferably in the future for this use case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "KCW8pxoMt6ZF",
        "outputId": "1b9e1308-76ab-479b-daa5-2548686de33d"
      },
      "source": [
        "times = sorted(main_df.index.values)  # get the times\n",
        "last_5pct = sorted(main_df.index.values)[-int(0.05*len(times))]  # get the last 5% of the times\n",
        "validation_main_df = main_df[(main_df.index >= last_5pct)]  # make the validation data where the index is in the last 5%\n",
        "main_df = main_df[(main_df.index < last_5pct)]  # now the main_df is all the data up to the last 5%\n",
        "validation_main_df.head()\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BTC-USD_close</th>\n",
              "      <th>BTC-USD_volume</th>\n",
              "      <th>LTC-USD_close</th>\n",
              "      <th>LTC-USD_volume</th>\n",
              "      <th>ETH-USD_close</th>\n",
              "      <th>ETH-USD_volume</th>\n",
              "      <th>BCH-USD_close</th>\n",
              "      <th>BCH-USD_volume</th>\n",
              "      <th>future</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1534922100</th>\n",
              "      <td>6684.500000</td>\n",
              "      <td>0.969366</td>\n",
              "      <td>57.509998</td>\n",
              "      <td>66.463028</td>\n",
              "      <td>285.739990</td>\n",
              "      <td>194.228867</td>\n",
              "      <td>550.719971</td>\n",
              "      <td>5.058020</td>\n",
              "      <td>57.509998</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1534922160</th>\n",
              "      <td>6684.500000</td>\n",
              "      <td>0.611018</td>\n",
              "      <td>57.509998</td>\n",
              "      <td>3.616516</td>\n",
              "      <td>285.730011</td>\n",
              "      <td>11.172032</td>\n",
              "      <td>550.710022</td>\n",
              "      <td>0.136300</td>\n",
              "      <td>57.509998</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1534922220</th>\n",
              "      <td>6682.740234</td>\n",
              "      <td>1.121768</td>\n",
              "      <td>57.509998</td>\n",
              "      <td>13.260421</td>\n",
              "      <td>285.730011</td>\n",
              "      <td>1.411576</td>\n",
              "      <td>551.299988</td>\n",
              "      <td>75.830658</td>\n",
              "      <td>57.509998</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1534922280</th>\n",
              "      <td>6682.660156</td>\n",
              "      <td>0.912729</td>\n",
              "      <td>57.509998</td>\n",
              "      <td>19.851404</td>\n",
              "      <td>285.739990</td>\n",
              "      <td>3.382381</td>\n",
              "      <td>551.299988</td>\n",
              "      <td>8.701156</td>\n",
              "      <td>57.500000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1534922340</th>\n",
              "      <td>6682.450195</td>\n",
              "      <td>0.334119</td>\n",
              "      <td>57.509998</td>\n",
              "      <td>17.104265</td>\n",
              "      <td>285.730011</td>\n",
              "      <td>0.429721</td>\n",
              "      <td>551.179993</td>\n",
              "      <td>9.790523</td>\n",
              "      <td>57.509998</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            BTC-USD_close  BTC-USD_volume  ...     future  target\n",
              "time                                       ...                   \n",
              "1534922100    6684.500000        0.969366  ...  57.509998       0\n",
              "1534922160    6684.500000        0.611018  ...  57.509998       0\n",
              "1534922220    6682.740234        1.121768  ...  57.509998       0\n",
              "1534922280    6682.660156        0.912729  ...  57.500000       0\n",
              "1534922340    6682.450195        0.334119  ...  57.509998       0\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4gE8FZauMsP"
      },
      "source": [
        "# function to preprocess the data\n",
        "def preprocess_df2(df):\n",
        "  df = df.drop('future', 1) # We don't need future col anymore since we've already obtained target\n",
        "\n",
        "  # Scaling our columns\n",
        "  for col in df.columns:\n",
        "    if col != \"target\":\n",
        "      df[col] = df[col].pct_change() # Normalize the columns bases on percent change\n",
        "      df.dropna(inplace=True)\n",
        "      df[col] = preprocessing.scale(df[col].values)\n",
        "  \n",
        "  df.dropna(inplace=True)\n",
        "\n",
        "  sequential_data = []\n",
        "  prev_days = deque(maxlen = SEQ_LEN)\n",
        "  \n",
        "  for i in df.values:\n",
        "    prev_days.append([n for n in i[:-1]])\n",
        "    if prev_days == SEQ_LEN:\n",
        "      sequential_data.append([np.array(prev_days), i[-1]])\n",
        "  \n",
        "  random.shuffle(sequential_data)\n",
        "\n",
        "  buys = []\n",
        "  sells = []\n",
        "\n",
        "  for seq, target in sequential_data:\n",
        "    if target == 0:\n",
        "      sells.append([seq, target])\n",
        "    elif target == 1:\n",
        "      buys.append([seq, target])\n",
        "  \n",
        "  random.shuffle(buys)\n",
        "  random.shuffle(sells)\n",
        "\n",
        "  lower = min(len(buys), len(sells)) # Which series is shorter\n",
        "\n",
        "  buys = buys[:lower]\n",
        "  sells = sells[:lower]\n",
        "\n",
        "  sequential_data = buys + sells\n",
        "\n",
        "  random.shuffle(sequential_data)\n",
        "\n",
        "  X = []\n",
        "  y = []\n",
        "\n",
        "  for seq, target in sequential_data:\n",
        "    X.append(seq)\n",
        "    y.aapend(target)\n",
        "\n",
        "  return np.array(X), y"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUz4OIc16G98"
      },
      "source": [
        "def preprocess_df(df):\n",
        "    df = df.drop(\"future\", 1)  # don't need this anymore.\n",
        "\n",
        "    for col in df.columns:  # go through all of the columns\n",
        "        if col != \"target\":  # normalize all ... except for the target itself!\n",
        "            df[col] = df[col].pct_change()  # pct change \"normalizes\" the different currencies (each crypto coin has vastly diff values, we're really more interested in the other coin's movements)\n",
        "            df.dropna(inplace=True)  # remove the nas created by pct_change\n",
        "            df[col] = preprocessing.scale(df[col].values)  # scale between 0 and 1.\n",
        "\n",
        "    df.dropna(inplace=True)  # cleanup again... jic.\n",
        "\n",
        "\n",
        "    sequential_data = []  # this is a list that will CONTAIN the sequences\n",
        "    prev_days = deque(maxlen=SEQ_LEN)  # These will be our actual sequences. They are made with deque, which keeps the maximum length by popping out older values as new ones come in\n",
        "\n",
        "    for i in df.values:  # iterate over the values\n",
        "        prev_days.append([n for n in i[:-1]])  # store all but the target\n",
        "        if len(prev_days) == SEQ_LEN:  # make sure we have 60 sequences!\n",
        "            sequential_data.append([np.array(prev_days), i[-1]])  # append those bad boys!\n",
        "\n",
        "    random.shuffle(sequential_data)  # shuffle for good measure.\n",
        "\n",
        "    buys = []  # list that will store our buy sequences and targets\n",
        "    sells = []  # list that will store our sell sequences and targets\n",
        "\n",
        "    for seq, target in sequential_data:  # iterate over the sequential data\n",
        "        if target == 0:  # if it's a \"not buy\"\n",
        "            sells.append([seq, target])  # append to sells list\n",
        "        elif target == 1:  # otherwise if the target is a 1...\n",
        "            buys.append([seq, target])  # it's a buy!\n",
        "\n",
        "    random.shuffle(buys)  # shuffle the buys\n",
        "    random.shuffle(sells)  # shuffle the sells!\n",
        "\n",
        "    lower = min(len(buys), len(sells))  # what's the shorter length?\n",
        "\n",
        "    buys = buys[:lower]  # make sure both lists are only up to the shortest length.\n",
        "    sells = sells[:lower]  # make sure both lists are only up to the shortest length.\n",
        "\n",
        "    sequential_data = buys+sells  # add them together\n",
        "    random.shuffle(sequential_data)  # another shuffle, so the model doesn't get confused with all 1 class then the other.\n",
        "\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for seq, target in sequential_data:  # going over our new sequential data\n",
        "        X.append(seq)  # X is the sequences\n",
        "        y.append(target)  # y is the targets/labels (buys vs sell/notbuy)\n",
        "\n",
        "    return np.array(X), y  # return X and y...and make X a numpy array!\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLQ0Asnxwcfy",
        "outputId": "bbf75d7b-9f3e-4e4a-b9f6-99fa102b6e6a"
      },
      "source": [
        "train_x, train_y = preprocess_df(main_df)\n",
        "val_x, val_y = preprocess_df(validation_main_df)\n",
        "\n",
        "print(f\"train data: {len(train_x)} validation: {len(val_x)}\")\n",
        "print(f\"Dont buys: {train_y.count(0)}, buys: {train_y.count(1)}\")\n",
        "print(f\"VALIDATION Dont buys: {val_y.count(0)}, buys: {val_y.count(1)}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train data: 69188 validation: 3062\n",
            "Dont buys: 34594, buys: 34594\n",
            "VALIDATION Dont buys: 1531, buys: 1531\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvzcVZvz3AEs"
      },
      "source": [
        "EPOCHS = 10\n",
        "BATCH_SIZE = 64\n",
        "NAME = f\"{SEQ_LEN}-SEQ-{FUTURE_PERIOD_PREDICT}-PRED-{int(time.time())}\"  # a unique name for the model"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l35RaC4O8FU1"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(train_x.shape[1:]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())  #normalizes activation outputs, same reason you want to normalize your input data.\n",
        "\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(2, activation='softmax'))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ad1Q294rd7WG"
      },
      "source": [
        "opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
        "# Compile model\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=opt,\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSqzuxn4d99X",
        "outputId": "d1f36013-459f-4a97-fc11-3fac14ff03cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 60, 128)           70144     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 60, 128)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 60, 128)           512       \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 60, 128)           131584    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 60, 128)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 60, 128)           512       \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 339,042\n",
            "Trainable params: 338,274\n",
            "Non-trainable params: 768\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhMudI-MeCYC"
      },
      "source": [
        "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zv9ovWfeeFzo"
      },
      "source": [
        "filepath = \"RNN_Final-{epoch:02d}-{val_acc:.3f}\"  # unique file name that will include the epoch and the validation acc for that epoch\n",
        "checkpoint = ModelCheckpoint(\"models/{}.model\".format(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')) # saves only the best ones\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJdJL6ypeM83",
        "outputId": "dd357d9a-a4c9-47f7-95d9-db21cb791568",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "# Train model\n",
        "history = model.fit(\n",
        "    train_x, train_y,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(val_x, val_y),\n",
        "    callbacks=[tensorboard, checkpoint],\n",
        ")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-ecc15a830299>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1062\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1097\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m     self._adapter = adapter_cls(\n\u001b[1;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    962\u001b[0m         \u001b[0;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m         \"input: {}, {}\".format(\n\u001b[0;32m--> 964\u001b[0;31m             _type_name(x), _type_name(y)))\n\u001b[0m\u001b[1;32m    965\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter_cls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m     raise RuntimeError(\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class 'numpy.ndarray'>, (<class 'list'> containing values of types {\"<class 'numpy.float64'>\"})"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGP9K8rTeUlg"
      },
      "source": [
        "# Score model\n",
        "score = model.evaluate(validation_x, validation_y, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "# Save model\n",
        "model.save(\"models/{}\".format(NAME))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}